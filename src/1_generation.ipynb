{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b218d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7a0799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "# dan jurafsky's string2string library\n",
    "from string2string.similarity import JaroSimilarity\n",
    "\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "from prompting.prompts import DataTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e41529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../abstracts_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbdb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages(DataTemplates().medicine_abstract_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b906323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_row(text: str, temperature) -> str:\n",
    "    llm = ChatOpenAI(temperature=temperature)\n",
    "    chat = LLMChain(llm=llm, prompt=template)\n",
    "    output = chat.run({\"text\": text})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12d68b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [0.3, 0.5, 0.7, 0.9, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6b34654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a00b1a6d133e74641c9e694f3461860d in your message.).\n"
     ]
    }
   ],
   "source": [
    "generations = []\n",
    "for t in temperatures:\n",
    "    for i, row in df.iterrows():\n",
    "        text = row[\"texts\"]\n",
    "        generations.append({\"temperature\": t, \"text\": generate_row(text)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a33f8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(generations).reset_index()\n",
    "df2[\"intex\"] = df2[\"index\"].apply(lambda x: x % 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423311a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05c63c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[temperatures] = df2.pivot(index=\"intex\", columns=\"temperature\", values=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1a73392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/generated_outputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e308237d",
   "metadata": {},
   "source": [
    "### We need to determine how likely the texts are to be generated by ChatGPT.\n",
    "We will generate 10 texts for each abstract. We will then compare the similarity between the real human answers and GPT-answers. \n",
    "\n",
    "1. Select 3 generations and measure the average similarity to the other ChatGPT answers\n",
    "2. Select the real texts and see how similar they are to the generations.\n",
    "3. Use the MTurk data and measure how similar the texts are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2679a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Jaro similarity score between FARMVILLE and FAREMVIEL is 0.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the JaroSimilarity class\n",
    "jaro_similarity = JaroSimilarity()\n",
    "\n",
    "# Compute the Jaro similarity scores of the following pairs of words\n",
    "score = jaro_similarity.compute('FARMVILLE', 'FAREMVIEL')\n",
    "print(f'The Jaro similarity score between FARMVILLE and FAREMVIEL is {score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea4e4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string2string.alignment import LongestCommonSubsequence\n",
    "\n",
    "# Create an instance of the LongestCommonSubsequence class\n",
    "lcsubsequence = LongestCommonSubsequence()\n",
    "\n",
    "length, candidates = lcsubsequence.compute(\n",
    "    str1=\"abcdefghijklmnopqrstuvwxyz\",\n",
    "    str2=\"xzytawbvckjfhgslrqponmedui\", \n",
    "    returnCandidates=True\n",
    ")\n",
    "\n",
    "# Print the length of the longest common subsequence\n",
    "print(f'The length of the longest common subsequence is {length}.')\n",
    "\n",
    "# Print the candidates\n",
    "print(f'The candidates are {candidates}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
